{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EGqrrXzv2-Cn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3513f647-e544-4688-9342-31f7e4597dd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 126897 files and directories currently installed.)\n",
            "Preparing to unpack chrome.deb ...\n",
            "Unpacking google-chrome-stable (138.0.7204.183-1) over (138.0.7204.183-1) ...\n",
            "Setting up google-chrome-stable (138.0.7204.183-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "✅ Success! Page title: Example Domain\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "import dateutil\n",
        "import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import urllib3\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "# 📦 Install Google Chrome\n",
        "!wget -q -O chrome.deb https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!dpkg -i chrome.deb || apt-get -fy install > /dev/null\n",
        "\n",
        "# 📥 Get matching ChromeDriver\n",
        "import os, re, requests, zipfile, io\n",
        "\n",
        "# Get Chrome version\n",
        "version_output = !google-chrome --version\n",
        "major_version = re.search(r'(\\d+)\\.', version_output[0]).group(1)\n",
        "\n",
        "# Get matching ChromeDriver URL\n",
        "resp = requests.get('https://googlechromelabs.github.io/chrome-for-testing/last-known-good-versions-with-downloads.json')\n",
        "driver_info = resp.json()['channels']['Stable']['downloads']['chromedriver']\n",
        "driver_url = next(d['url'] for d in driver_info if d['platform'] == 'linux64')\n",
        "\n",
        "# Download and extract ChromeDriver\n",
        "driver_zip = requests.get(driver_url)\n",
        "z = zipfile.ZipFile(io.BytesIO(driver_zip.content))\n",
        "extract_path = \"/usr/bin/chromedriver-linux64\"\n",
        "z.extractall(extract_path)\n",
        "os.chmod(f\"{extract_path}/chromedriver\", 0o755)\n",
        "\n",
        "# 🔄 Fix symlink safely\n",
        "if os.path.islink(\"/usr/bin/chromedriver\") or os.path.exists(\"/usr/bin/chromedriver\"):\n",
        "    os.remove(\"/usr/bin/chromedriver\")\n",
        "os.symlink(f\"{extract_path}/chromedriver\", \"/usr/bin/chromedriver\")\n",
        "\n",
        "# ✅ Install Python packages\n",
        "!pip install -q selenium beautifulsoup4\n",
        "\n",
        "# ✅ Test it works\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "driver = webdriver.Chrome(service=Service(\"/usr/bin/chromedriver\"), options=chrome_options)\n",
        "driver.get(\"https://example.com\")\n",
        "print(\"✅ Success! Page title:\", driver.title)\n",
        "driver.quit()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "API_KEY = userdata.get('NY_TIMES_KEY')"
      ],
      "metadata": {
        "id": "h3kC2_4w3JQq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def send_request(date):\n",
        "    base_url = 'https://api.nytimes.com/svc/archive/v1/'\n",
        "    url = base_url + '/' + date[0] + '/' + date[1] + '.json?api-key=' + API_KEY\n",
        "    try:\n",
        "        response = requests.get(url, verify=False).json()\n",
        "    except Exception:\n",
        "        return None\n",
        "    time.sleep(6)\n",
        "    return response\n",
        "\n",
        "\n",
        "def is_valid(article, date):\n",
        "    is_in_range = date > start and date < end\n",
        "    has_headline = type(article['headline']) == dict and 'main' in article['headline'].keys()\n",
        "    return is_in_range and has_headline\n",
        "\n",
        "\n",
        "def parse_response(response):\n",
        "    data = {'headline': [],\n",
        "        'date': [],\n",
        "        'web_url': [],\n",
        "        'doc_type': [],\n",
        "        'lead_paragraph': [],\n",
        "        'material_type': [],\n",
        "        'author': [],\n",
        "        'section': [],\n",
        "        'subsection': [],\n",
        "        'keywords': []}\n",
        "\n",
        "    articles = response['response']['docs']\n",
        "    for article in articles:\n",
        "        date = dateutil.parser.parse(article['pub_date']).date()\n",
        "        if is_valid(article, date):\n",
        "            data['date'].append(date)\n",
        "            data['headline'].append(article['headline']['main'])\n",
        "            if 'section_name' in article:\n",
        "                data['section'].append(article['section_name'])\n",
        "            else:\n",
        "                data['section'].append(None)\n",
        "            if 'lead_paragraph' in article:\n",
        "                data['lead_paragraph'].append(article['lead_paragraph'])\n",
        "            else:\n",
        "                data['lead_paragraph'].append(None)\n",
        "            if 'web_url' in article:\n",
        "                data['web_url'].append(article['web_url'])\n",
        "            else:\n",
        "                data['web_url'].append(None)\n",
        "            if 'subsection_name' in article:\n",
        "                data['subsection'].append(article['subsection_name'])\n",
        "            else:\n",
        "                data['subsection'].append(None)\n",
        "            if 'byline' in article:\n",
        "                data['author'].append(article['byline']['original'])\n",
        "            else:\n",
        "                data['author'].append(None)\n",
        "            data['doc_type'].append(article['document_type'])\n",
        "            if 'type_of_material' in article:\n",
        "                data['material_type'].append(article['type_of_material'])\n",
        "            else:\n",
        "                data['material_type'].append(None)\n",
        "            keywords = [keyword['value'] for keyword in article['keywords'] if keyword['name'] == 'subject']\n",
        "            data['keywords'].append(keywords)\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "def get_data(dates):\n",
        "    total = 0\n",
        "    print('Date range: ' + str(dates[0]) + ' to ' + str(dates[-1]))\n",
        "    if not os.path.exists('headlines'):\n",
        "        os.mkdir('headlines')\n",
        "    for date in dates:\n",
        "        print('Working on ' + str(date) + '...')\n",
        "        csv_path = 'headlines/' + date[0] + '-' + date[1] + '.csv'\n",
        "        if not os.path.exists(csv_path): # If we don't already have this month\n",
        "            response = send_request(date)\n",
        "            if response is not None:\n",
        "                df = parse_response(response)\n",
        "                total += len(df)\n",
        "                df.to_csv(csv_path, index=False)\n",
        "                print('Saving ' + csv_path + '...')\n",
        "    print('Number of articles collected: ' + str(total))"
      ],
      "metadata": {
        "id": "aSDRXhSU3JS4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = datetime.date(2025, 1, 1)\n",
        "end = datetime.date(2025, 2, 15)"
      ],
      "metadata": {
        "id": "xfHkU-BT3JVX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "months = [x.split(' ') for x in pd.date_range(start, end, freq='MS').strftime(\"%Y %-m\").tolist()]"
      ],
      "metadata": {
        "id": "6MuDrhq-3diI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_data(months)"
      ],
      "metadata": {
        "id": "F-RIq3oM3dn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0bdc397-ab48-4119-a1dd-e5204224d5a0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date range: ['2025', '1'] to ['2025', '2']\n",
            "Working on ['2025', '1']...\n",
            "Saving headlines/2025-1.csv...\n",
            "Working on ['2025', '2']...\n",
            "Saving headlines/2025-2.csv...\n",
            "Number of articles collected: 6088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "os.chdir(\"/content/headlines\") ## use Google Colab"
      ],
      "metadata": {
        "id": "RE-EB51o3duw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extension = 'csv'\n",
        "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]"
      ],
      "metadata": {
        "id": "VW_gz-m13rcX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combine in a single file\n",
        "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
        "#export to csv\n",
        "combined_csv.to_csv( \"combined_csv.csv\", index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "n1DDqwUD3td0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_body(url):\n",
        "    driver.get(url)\n",
        "    article_text = ''\n",
        "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "    paragraph = soup.find_all('p')\n",
        "    for i in paragraph:\n",
        "        a = i.get_text()\n",
        "        if a != 'Advertisement' and a != 'Supported by' and a != 'Send any friend a story' and a != 'As a subscriber, you have 10 gift articles to give each month. Anyone can read what you share.' and not a.startswith(\"By\"):\n",
        "            article_text += a\n",
        "            article_text += \" \"\n",
        "    time.sleep(8)\n",
        "    return article_text"
      ],
      "metadata": {
        "id": "zQ0-27fi38BO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"combined_csv.csv\")"
      ],
      "metadata": {
        "id": "WgBJvUu64BFe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## CREATE A NEW COLUMN IN THE DATAFRAME CALLED \"article_doby\" WHERE WE ARE GOING TO APPEND THE TEXT RETRIEVE FROM\n",
        "## THE URL. NOTE: web_url REFERS TO THE COLUMN IN THE DATASET CONTAINING THE URL OF THE ARTICLE TO PASS TO get_body.\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "driver = webdriver.Chrome(service=Service(\"/usr/bin/chromedriver\"), options=chrome_options)\n",
        "df['article_body'] = df.head(100).apply(lambda x: get_body(x.web_url), axis=1)"
      ],
      "metadata": {
        "id": "XJJciMa04FDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for article in df['article_body'].dropna():\n",
        "    print(article)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHjJyGYi4l14",
        "outputId": "3e9e0133-2170-45d4-a029-bfe5eb068114"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We and our vendors use cookies and similar methods (“Cookies”) to recognize visitors and remember their preferences. We also use Cookies for a variety of purposes, including analytics, to measure marketing effectiveness and to target and measure the effectiveness of ads. You can accept or reject the use of Cookies for individual purposes below. Some vendors process your data on the basis of their legitimate interest - you can object to such processing below. Your preferences will be saved in a cookie named “fides_consent” for a maximum duration of 12 months, as well as in your registered user account if you are logged in. If you previously accepted these methods through our prior banner, then we will use your data for targeting. Your preferences will apply on nytimes.com, as well as our News, Cooking, Games and Audio apps. Your preferences here are unrelated to Apple’s App Tracking Transparency Framework. THEATER REVIEW The paint on the balconies of the Majestic Theater looks chipped and the electronic drum machine sounds like something left over from a music video from the 1980's. But \"The Phantom of the Opera\" really shows its age (17 years and running) when the signature special effect is presented. Musicals have opened and closed in the time it takes that chandelier to lumber to the floor. Looking like one of Ed Wood's teetering flying saucers, it crashes to the stage with the force of a shopping cart, the biggest, most extravagant anticlimax in town. But what do you expect? It was designed during the Reagan administration. For a top-of-the-line chandelier, you will have to wait for the $40 million production of \"Phantom\" opening in Las Vegas next spring. But if the technology of the Broadway show seems a bit quaint, the real news is that the rest of the production has grown old gracefully. Judging by sheer invention, emotional punch and onstage talent, the venerable blockbuster still beats out almost all of the whippersnappers currently on Broadway. Maria Bjornson's flamboyant gothic design and Harold Prince's fantastical staging still have the gleam of finely polished professionalism. Led by the current Phantom (there have been 10 after Michael Crawford), Hugh Panaro, an up-and-coming musical theater star who finds the right mix of shock and schmaltz, most of the cast retains the freshness of opening night. That does not mean that Andrew Lloyd Webber haters, a large and very grumpy contingent, will be won over. Sorry, \"The Music of the Night\" hasn't changed. Nor has Charles Hart's bumbling lyrics (\"You have brought me to that moment when words run dry\"). But for those sentimental souls looking for a popular entertainment to transport them to a baroque, romantic new world with a powerful smoke machine, \"Phantom,\" I'm happy to report, still delivers the goods. Which is especially impressive, given that not long ago, the musical seemed to be on its last legs. By the fall of 2003, its peers \"Miss Saigon,\" \"Cats\" and \"Les Misérables\" had faded away. Ticket sales were down and rumors of its demise were common around Broadway. Flash-forward to today: crowds are lined up around the corner to see the show, which regularly sells out. Last week, 99 percent of the seats were filled. In January, barring a strike, disaster or nuclear holocaust, \"Phantom\" will eclipse \"Cats\" as the longest-running show in Broadway history. What happened? For one thing, it received a boost from Joel Schumacher's film version of the musical, which opened in December. Even though it wasn't a smash hit, the movie introduced a new audience to the show (as evidenced by the large number of young girls at the Majestic) and reminded old ones how superior the musical is. In fact, the bombastic film may be the only thing that makes the musical look understated. We are having trouble retrieving the article content. Please enable JavaScript in your browser settings. Thank you for your patience while we verify access. If you are in Reader mode please exit and log into your Times account, or subscribe for all of The Times. Thank you for your patience while we verify access. Already a subscriber? Log in. Want all of The Times? Subscribe. Make sense of the day’s news and ideas. Catch up on big news, and wind down to end your day. The biggest stories of our time, in 20 minutes a day. Get what you need to know to start your day. Original analysis on the week’s biggest global stories. The latest news for any part of the world you select. Backstories and analysis from our Canadian correspondents. The most crucial business and policy news you need to know. Our best tech reporting from the week. Our tech journalists help you make sense of the rapidly changing tech world. Reviews, news and features to help you find your next read. Streaming TV and movie recommendations. The podcast that takes you inside the literary world. Pop music news, new songs and albums, and artists of note. Unwind with stories about culture and the way we live. Essential news and guidance to live your healthiest life. The complicated love lives of real people. Mapping the new world order through interviews and conversations. You've heard the news, here's what to make of it. Discussions of ideas that matter, plus book recommendations. Podcasts and narrated articles covering news, tech, culture and more.Go to Audio Come on in, the culture's fine. Your morning listen. Top stories, in 10 minutes. An investigation into\n",
            "C-sections. Our editors share their favorite listens from The Times and beyond. Be the first to know about our new shows. Word games, logic puzzles and crosswords, including an extensive archive.Go to Games Spelling Bee  The Mini Crossword  Wordle  The Crossword  Strands  Connections  Sudoku  Letter Boxed  Tiles  Puzzles, brain teasers, solving tips and more. Get an easy version of one of the hardest crossword puzzles of the week. Recipes, advice and inspiration for everyday cooking, special occasions and more.Go to Cooking New recipes, easy dinner ideas and smart kitchen tips from Melissa Clark, Sam Sifton and our New York Times Cooking editors. Delicious vegetarian recipes and tips from Tanya Sichynsky. Dinner ideas for busy people from Emily Weinstein. Reviews and recommendations for thousands of products.Go to Wirecutter The best independent reviews, expert advice and intensively researched deals. Step-by-step advice on how to keep everything in your home squeaky clean. Personalized coverage of your sports teams and leagues.Go to The Athletic Delivering the top stories in sports, Sunday to Friday. The top stories in the NFL, from Jacob Robinson with Dianna Russini. Connections:\n",
            "Sports Edition  Connections Coach  \n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}