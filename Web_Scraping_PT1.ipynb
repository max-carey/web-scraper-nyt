{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGqrrXzv2-Cn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "import dateutil\n",
        "import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import urllib3\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = 'YOUR_API_KEY'"
      ],
      "metadata": {
        "id": "h3kC2_4w3JQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def send_request(date):\n",
        "    base_url = 'https://api.nytimes.com/svc/archive/v1/'\n",
        "    url = base_url + '/' + date[0] + '/' + date[1] + '.json?api-key=' + API_KEY\n",
        "    try:\n",
        "        response = requests.get(url, verify=False).json()\n",
        "    except Exception:\n",
        "        return None\n",
        "    time.sleep(6)\n",
        "    return response\n",
        "\n",
        "\n",
        "def is_valid(article, date):\n",
        "    is_in_range = date > start and date < end\n",
        "    has_headline = type(article['headline']) == dict and 'main' in article['headline'].keys()\n",
        "    return is_in_range and has_headline\n",
        "\n",
        "\n",
        "def parse_response(response):\n",
        "    data = {'headline': [],  \n",
        "        'date': [], \n",
        "        'web_url': [],\n",
        "        'doc_type': [],\n",
        "        'lead_paragraph': [],\n",
        "        'material_type': [],\n",
        "        'author': [],\n",
        "        'section': [],\n",
        "        'subsection': [],\n",
        "        'keywords': []}\n",
        "    \n",
        "    articles = response['response']['docs'] \n",
        "    for article in articles: \n",
        "        date = dateutil.parser.parse(article['pub_date']).date()\n",
        "        if is_valid(article, date):\n",
        "            data['date'].append(date)\n",
        "            data['headline'].append(article['headline']['main']) \n",
        "            if 'section_name' in article:\n",
        "                data['section'].append(article['section_name'])\n",
        "            else:\n",
        "                data['section'].append(None)\n",
        "            if 'lead_paragraph' in article:\n",
        "                data['lead_paragraph'].append(article['lead_paragraph'])\n",
        "            else:\n",
        "                data['lead_paragraph'].append(None)\n",
        "            if 'web_url' in article:\n",
        "                data['web_url'].append(article['web_url'])\n",
        "            else:\n",
        "                data['web_url'].append(None)\n",
        "            if 'subsection_name' in article:\n",
        "                data['subsection'].append(article['subsection_name'])\n",
        "            else:\n",
        "                data['subsection'].append(None)\n",
        "            if 'byline' in article:\n",
        "                data['author'].append(article['byline']['original'])\n",
        "            else:\n",
        "                data['author'].append(None)\n",
        "            data['doc_type'].append(article['document_type'])\n",
        "            if 'type_of_material' in article: \n",
        "                data['material_type'].append(article['type_of_material'])\n",
        "            else:\n",
        "                data['material_type'].append(None)\n",
        "            keywords = [keyword['value'] for keyword in article['keywords'] if keyword['name'] == 'subject']\n",
        "            data['keywords'].append(keywords)\n",
        "    return pd.DataFrame(data) \n",
        "\n",
        "\n",
        "def get_data(dates):\n",
        "    total = 0\n",
        "    print('Date range: ' + str(dates[0]) + ' to ' + str(dates[-1]))\n",
        "    if not os.path.exists('headlines'):\n",
        "        os.mkdir('headlines')\n",
        "    for date in dates:\n",
        "        print('Working on ' + str(date) + '...')\n",
        "        csv_path = 'headlines/' + date[0] + '-' + date[1] + '.csv'\n",
        "        if not os.path.exists(csv_path): # If we don't already have this month \n",
        "            response = send_request(date)\n",
        "            if response is not None:\n",
        "                df = parse_response(response)\n",
        "                total += len(df)\n",
        "                df.to_csv(csv_path, index=False)\n",
        "                print('Saving ' + csv_path + '...')\n",
        "    print('Number of articles collected: ' + str(total))"
      ],
      "metadata": {
        "id": "aSDRXhSU3JS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end = datetime.date(2020, 12, 31)\n",
        "start = datetime.date(2000, 1, 1)"
      ],
      "metadata": {
        "id": "xfHkU-BT3JVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "months = [x.split(' ') for x in pd.date_range(start, end, freq='MS').strftime(\"%Y %-m\").tolist()]"
      ],
      "metadata": {
        "id": "6MuDrhq-3diI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_data(months)"
      ],
      "metadata": {
        "id": "F-RIq3oM3dn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "os.chdir(\"/content/headlines\") ## use Google Colab"
      ],
      "metadata": {
        "id": "RE-EB51o3duw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extension = 'csv'\n",
        "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]"
      ],
      "metadata": {
        "id": "VW_gz-m13rcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combine in a single file\n",
        "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
        "#export to csv\n",
        "combined_csv.to_csv( \"combined_csv.csv\", index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "n1DDqwUD3td0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}